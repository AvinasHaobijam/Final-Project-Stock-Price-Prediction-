import pandas as pd
stock_data = pd.read_csv('./NFLX.csv',index_col='date')
stock_data.head()
import matplotlib.dates as mdates
 import matplotlib.pyplot as plt

 import datetime as dt

 plt.figure(figsize=(15,10))

 plt.gea().xaxis. set_major_formatter(mdates.DateFormatter('%y-%m-%d"))

 plt.gea() .xaxis. set_major_locator(ndates.DayLocator (interval=60))

 x_dates = [dt.datetime.strptime(d, ‘%v-%n-%d").date() for d in stock_data.index.values]


 plt.plot(x_dates, stock _data['High'], label='High')

 plt.plot(x_dates, stock _data[‘Low'], label='Low')

 plt.xlabel('Time Scale’)

 plt.ylabel('Scaled USD')

 plt.legend()

 plt.gcf().autofmt_xdate()

 plt. show()
import matplotlib.pyplot as plt

 import pandas as pd

 import numpy as np

 from tensorflow keras.models import Sequential

 from tensorflow.keras. layers import Dense

 from tensorflow keras. layers import LSTH

 from tensorflow.keras. layers import Dropout

 from tensorflow.keras.layers import *

 from tensorflow.keras. callbacks import EarlyStopping

 from sklearn.preprocessing import MinWaxscaler, Standardscaler
 from sklearn.metrics import mean_squared_error

 from sklearn.metrics import mean absolute percentage error
 from sklearn.model selection import train _test_split

 from sklearn.model selection import TimeSeriesSplit

 from sklearn.metrics import mean_squared_error

target_y=  stock_data['Close']
X_feat + stock_data.iloc[:,0:3]

﻿
 #Feature Scaling
 sc = StandardScaler()
 X_ft = sc.fit_transform(X_feat.values)
 X_ft = pd.DataFrame(columns=X_feat.columns, data=X_ft, index=X_feat.index)


﻿

 def 1stm_split(data, n_steps): 2 
x, y = [], []
for i in range(len(data)-n_steps+1): 
x.append(data[i:i + n_steps, -1]) 
y.append(data[i+n_steps-1, -1])
return np.array(X), np.array(y)

﻿
 x1, y1=1stm_split(stock_data_ft.values, n_steps=2)
 train_split-0.8
 split_idx= int(np.ceil(len(X1)*train_split)) 5 date_index = stock_data_ft.index

 X_train, X_test = X1[:split_idx], X1[split_idx:]
 y_train, y_test = y1[:split_idx], y1[split_idx:]
 X_train_date, X_test_date = date_index[:split_idx], date_index[split_idx:]

 print(X1.shape, X_train. shape, X_test.shape, y_test.shape)


1stm = Sequential()
1stm.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]),
activation='relu', return_sequences=True))
 1stm.add(Dense(1))
 1stm.compile(loss='mean_squared_error', optimizer='adam') 
1stm.summary()

﻿
history-1stm.fit(x_train, y_train,
epochs=100, batch_size=4,
verbose=2, shuffle=False)

﻿
 y_pred=1stm.predict(x_test)

﻿
rmse = mean_squared_error (y_test, y_pred, squared=False)
mape = mean_absolute_percentage_error(y_test, y_pred)
print("RSME: ",rmse)
print("MAPE: ", mape)

﻿
1stm=Sequential()
1stm.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), 3|| | || || activation='relu', return_sequences=True))
1stm.add(LSTM(50, activation='relu'))
1stm.add(Dense (1))
1stm.compile(loss='mean_squared_error', optimizer=' adam')
1stm.summary()

﻿
rmse = mean_squared_error(y_test, y_pred, squared-False) 
mape = mean_absolute_percentage_error(y_test, y_pred) 
print("RSME: ", rmse)
print("MAPE: ", mape)

﻿
 n_steps=10
 X1, y1 = 1stm_split(stock_data_ft.values, n_steps-n_steps)

 train_split-0.8
 split_idx= int(np.ceil(len(X1)*train_split))
 date_index = stock_data_ft.index

 X_train, X_test = X1[:split_idx], X1[split_idx:]
 y_train, y_test = y1[:split_idx], y1[split_idx:]
 X_train_date, X_test_date = date_index[:split_idx], date_index [split_idx:-n_steps]

 print(X1. shape, X_train.shape, X_test.shape, X_test_date.shape, y_test.shape)

﻿
rmse = mean_squared_error(y_test, y_pred, squared=False) 
mape = mean_absolute_percentage_error(y_test, y_pred)
print("RSME: ",rmse)
print("MAPE: ", mape)

﻿
 train_split = 0.8
 split_idx= int(np.ceil(len(stock_data)*train_split))
 train = stock_data[ [ 'Close']].iloc[:split_idx]
 test = stock_data[ ['Close']].iloc[split_idx:]
 test_pred = np.array([train.rolling (10).mean().iloc[-1]]*len(test)).reshape((-1,1))
 print('Test RMSE: %.3f' % mean_squared_error(test, test_pred, squared-False))
 print('Test MAPE: %.3f' % mean_absolute_percentage_error(test, test_pred))
 plt.figure(figsize=(10,5))
 plt.plot(test)
 plt.plot(test_pred)
 plt.show()

﻿
 from statsmodels.tsa.api import SimpleExpSmoothing

X = stock_data[['Close']].values
train_split = 0.8
split_idx= int(np.ceil(len(X)*train_split))
train = x[:split_idx]
test = x[split_idx:]
test_concat = np.array([]).reshape((0,1))

for i in range(len(test)):
train_fit = np.concatenate((train, np.asarray (test_concat)))
fit = SimpleExpSmoothing (np.asarray(train_fit)).fit(smoothing_level=0.2) test_pred fit. forecast (1)
test_concat = np.concatenate((np.asarray(test_concat), test_pred.reshape((-1,1))))
print('Test RMSE: %.3f' % mean_squared_error(test, test_concat, squared=False)) 
print('Test MAPE: %.3f' % mean_absolute_percentage_error(test, test_concat))





